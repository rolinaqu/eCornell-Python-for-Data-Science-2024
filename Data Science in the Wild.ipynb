{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "edf7da1d5cb4bf89d4c39225daf75c1c",
     "grade": false,
     "grade_id": "cell-adcd3e653f734bce",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "<h2>About this Project</h2>\n",
    "\n",
    "In this project, you will walk through how to approach data science problem for a dataset from scratch. The context of the problem is as follows: you are tasked to predict the severity of a patient's heart disease based on a set of medical attributes. We will restrict our attention to regression tree and walk you through how to approach this problem systematically.\n",
    "\n",
    "<h3>Evaluation</h3>\n",
    "\n",
    "<p><strong>This project must be successfully completed and submitted in order to receive credit for this course. Your score on this project will be included in your final grade calculation.</strong><p>\n",
    "    \n",
    "<p>You are expected to write code where you see <em># YOUR CODE HERE</em> within the cells of this notebook. Not all cells will be graded; code input cells followed by cells marked with <em>#Autograder test cell</em> will be graded. Upon submitting your work, the code you write at these designated positions will be assessed using an \"autograder\" that will run all test cells to assess your code. You will receive feedback from the autograder that will identify any errors in your code. Use this feedback to improve your code if you need to resubmit. Be sure not to change the names of any provided functions, classes, or variables within the existing code cells, as this will interfere with the autograder. Also, remember to execute all code cells sequentially, not just those you’ve edited, to ensure your code runs properly.</p>\n",
    "    \n",
    "<p>You can resubmit your work as many times as necessary before the submission deadline. If you experience difficulty or have questions about this exercise, use the Q&A discussion board to engage with your peers or seek assistance from the instructor.<p>\n",
    "\n",
    "<p>Before starting your work, please review <a href=\"https://s3.amazonaws.com/ecornell/global/eCornellPlagiarismPolicy.pdf\">eCornell's policy regarding plagiarism</a> (the presentation of someone else's work as your own without source credit).</p>\n",
    "\n",
    "<h3>Submit Code for Autograder Feedback</h3>\n",
    "\n",
    "<p>Once you have completed your work on this notebook, you will submit your code for autograder review. Follow these steps:</p>\n",
    "\n",
    "<ol>\n",
    "  <li><strong>Save your notebook.</strong></li>\n",
    "  <li><strong>Mark as Completed —</strong> In the blue menu bar along the top of this code exercise window, you’ll see a menu item called <strong>Education</strong>. In the <strong>Education</strong> menu, click <strong>Mark as Completed</strong> to submit your code for autograder/instructor review. This process will take a moment and a progress bar will show you the status of your submission.</li>\n",
    "\t<li><strong>Review your results —</strong> Once your work is marked as complete, the results of the autograder will automatically be presented in a new tab within the code exercise window. You can click on the assessment name in this feedback window to see more details regarding specific feedback/errors in your code submission.</li>\n",
    "  <li><strong>Repeat, if necessary —</strong> The Jupyter notebook will always remain accessible in the first tabbed window of the exercise. To reattempt the work, you will first need to click <strong>Mark as Uncompleted</strong> in the <strong>Education</strong> menu and then proceed to make edits to the notebook. Once you are ready to resubmit, follow steps one through three. You can repeat this procedure as many times as necessary.</li>\n",
    "</ol>\n",
    "<p>You can also download a copy of this notebook in multiple formats using the <strong>Download as</strong> option in the <strong>File</strong> menu above.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "ca2083189cace430509785a83927e68e",
     "grade": false,
     "grade_id": "cell-a388de7633cd305a",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Getting Started"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "0fc89dfba77fc79b6320bf5dbd9cba3c",
     "grade": false,
     "grade_id": "cell-e9e10d01c7b253bf",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You're running python 3.6.8\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "sys.path.append('/home/codio/workspace/.modules')\n",
    "from helper import *\n",
    "\n",
    "print('You\\'re running python %s' % sys.version.split(' ')[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "7eb63be842e9e8f4cfdcd70d262b8750",
     "grade": false,
     "grade_id": "cell-91646b69c3bc1e6f",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Data Science in the Wild\n",
    "\n",
    "### Part Zero: Understand the Type of Data and Information to be Extracted from the Data [Not Graded]\n",
    "\n",
    "For your convenience, we have split the data into training set and test set for you. The training data is in `heart_disease_train.csv` and the test data is in `heart_disease_test.csv`. You should do all your model selection on the training set and evaluate your _final_ model on the test data. Selecting model based on the test data is considered cheating so please refrain from doing so!\n",
    "    \n",
    "Before you begin, take a look at the two csv files and `attribute.txt`, which contains a description of each attribute in the csv files. You can download the files for review using the links below:\n",
    "\n",
    "* [heart_disease_train.csv](files/heart_disease_train.csv)\n",
    "* [heart_disease_test.csv](files/heart_disease_test.csv)\n",
    "* [attribute.txt](files/attribute.txt)\n",
    "\n",
    "### Part One: Implement `load_data` [Graded]\n",
    "\n",
    "Implement a function called **`load_data`**, which will load the given `.csv` file and return `X, y` data, where `X` are the patients' attributes and `y` is the severity of the patients' heart disease. Your function should:\n",
    "1. Open the file\n",
    "2. Read the comma-separated columns in the first line of the `.csv` (remember to strip the ending delimiters `'\\n'`).\n",
    "3. For each line except the first one, read the comma-separated column values, convert all values from `str` to `float`, and add to the data matrix (remember to strip the ending delimiters `'\\n'`).\n",
    "4. Use the `'label'` column for `y` if necessary.\n",
    "\n",
    "**Implementation Notes:**\n",
    "- In any case, do not include the `'label'` column in the data matrix &mdash; the model will then be able to use this feature to predict `y`!\n",
    "- The function should handle two explicit cases. With `label=True`, it should output the data matrix `X` and the corresponding label vector `y`; with `label=False`, it should output only the data matrix `X`.\n",
    "- Feel free to use `pd.read_csv` or other data loaders. Just make sure the returned `X, y` are NumPy arrays of shapes `nxd` and `n` respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "06ae8f1d4bf3054eb68850fd2fba1e0d",
     "grade": false,
     "grade_id": "cell-load_data",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def load_data(file='heart_disease_train.csv', label=True):\n",
    "    \"\"\"\n",
    "    Returns the data matrix and optionally the corresponding label vector.\n",
    "    \n",
    "    Input:\n",
    "        file: filename of the dataset\n",
    "        label: a boolean to decide whether to return the labels or not\n",
    "        \n",
    "    Output:\n",
    "        X: (numpy array) nxd data matrix of patient attributes\n",
    "        y: (numpy array) n-dimensional vector of labels (if label=False, y is not returned)\n",
    "    \"\"\"\n",
    "    X = None\n",
    "    y = None\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    #raise NotImplementedError()\n",
    "    txt = np.loadtxt(file, delimiter=\",\", dtype = str)\n",
    "    #print(X)\n",
    "    #truncate labels IF THERE ARE LABELS. IF THERE ARE NOT LABELS, DO NOT TRUNCATE \n",
    "    if label:\n",
    "        X = txt[1:,:-1]\n",
    "    else:\n",
    "        X = txt[1:,:]\n",
    "        \n",
    "    #y = txt[0:1,:]\n",
    "    y = txt[1:, -1]\n",
    "    \n",
    "    #convert to floats\n",
    "    X = X.astype(float)\n",
    "    y = y.astype(float)\n",
    "    \n",
    "    \n",
    "    #print(\"Shape of X: \" + np.shape(X))\n",
    "    #print(\"Shape of Y: \" + len(Y))\n",
    "    '''\n",
    "    #from 'Load Data in Python' notebook\n",
    "    #loads ALL entries as string values into the np array 'entries'\n",
    "    entries = []\n",
    "    with open(file, 'r') as f:\n",
    "        entries = [line.rstrip() for line in f.readlines() if len(x) > 0]\n",
    "    '''\n",
    "    \n",
    "    if label:\n",
    "        #if label is true\n",
    "        return X, y\n",
    "    else:\n",
    "        return X\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "9fa7ee9d950a1f567d4499b579bafc25",
     "grade": false,
     "grade_id": "cell-a4ad4015d5024026",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data matrix shape: (244, 13)\n",
      "Labels vector shape: (244,)\n"
     ]
    }
   ],
   "source": [
    "X, y = load_data()\n",
    "print(f'Training data matrix shape: {X.shape}')\n",
    "print(f'Labels vector shape: {y.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "3aa1c8dc07572c1c81b4ffdd4a2a36cc",
     "grade": false,
     "grade_id": "cell-load_data_selftest",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Test: load_data_test1 ... ✔ Passed!\n",
      "Running Test: load_data_test2 ... ✔ Passed!\n",
      "Running Test: load_data_test3 ... ✔ Passed!\n",
      "Running Test: load_data_test4 (Testing for correct types) ... ✔ Passed!\n",
      "Running Test: load_data_test5 (Testing training data for correctness) ... ✔ Passed!\n",
      "Running Test: load_data_test6 (training and testing data dimensions should match) ... ✔ Passed!\n",
      "Running Test: load_data_test7 (Testing test data for correctness) ... ✔ Passed!\n"
     ]
    }
   ],
   "source": [
    "# The following tests check that your load_data function reads in the correct number of rows, the correct number of unique values for y, and the same training data as the correct implementation\n",
    "\n",
    "Xtrain, ytrain = load_data()\n",
    "Xtrain_grader, ytrain_grader = load_data_grader()\n",
    "Xtest = load_data(file='heart_disease_test.csv', label=False)\n",
    "Xtest_grader = load_data_grader(file='heart_disease_test.csv', label=False)\n",
    "\n",
    "def load_data_test1():\n",
    "    return (len(Xtrain) == len(ytrain))\n",
    "\n",
    "def load_data_test2():\n",
    "    return (len(Xtrain) == len(Xtrain_grader))\n",
    "\n",
    "def load_data_test3():\n",
    "    y_unique = np.sort(np.unique(ytrain))\n",
    "    y_grader_unique = np.sort(np.unique(ytrain_grader))\n",
    "    \n",
    "    if len(y_unique) != len(y_grader_unique):\n",
    "        return False\n",
    "    else:\n",
    "        return np.linalg.norm(y_unique - y_grader_unique) < 1e-7\n",
    "    \n",
    "def load_data_test4():\n",
    "    return(type(Xtrain)==np.ndarray and type(ytrain)==np.ndarray and type(Xtest)==np.ndarray)\n",
    "\n",
    "def load_data_test5():\n",
    "    Xtrain.sort()\n",
    "    Xtrain_grader.sort()\n",
    "    return np.linalg.norm(Xtrain-Xtrain_grader)<1e-07\n",
    "\n",
    "def load_data_test6():\n",
    "    ntr,dtr=Xtrain.shape\n",
    "    nte,dte=Xtest.shape\n",
    "    return dtr==dte\n",
    "\n",
    "def load_data_test7():\n",
    "    Xtest.sort()\n",
    "    Xtest_grader.sort()\n",
    "    return np.linalg.norm(Xtest-Xtest_grader)<1e-07\n",
    "\n",
    "runtest(load_data_test1,'load_data_test1')\n",
    "runtest(load_data_test2,'load_data_test2')\n",
    "runtest(load_data_test3,'load_data_test3')\n",
    "runtest(load_data_test4,'load_data_test4 (Testing for correct types)')\n",
    "runtest(load_data_test5,'load_data_test5 (Testing training data for correctness)')\n",
    "runtest(load_data_test6,'load_data_test6 (training and testing data dimensions should match)')\n",
    "runtest(load_data_test7,'load_data_test7 (Testing test data for correctness)')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "0bbe4dfbb922ab2b853ad39f6127ed2e",
     "grade": true,
     "grade_id": "cell-load_data_test1",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Autograder test cell - worth 1 point\n",
    "# runs load_data test1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "59fbbb665728e84ec0d01658add23627",
     "grade": true,
     "grade_id": "cell-load_data_test2",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Autograder test cell - worth 1 point\n",
    "# runs load_data test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "7f19322071b93cfcc6c030e01d4d6e60",
     "grade": true,
     "grade_id": "cell-load_data_test3",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Autograder test cell - worth 1 point\n",
    "# runs load_data test3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "09e09db395fc07173e7b435d2426aa6a",
     "grade": true,
     "grade_id": "cell-load_data_test4",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Autograder test cell - worth 1 point\n",
    "# runs load_data test4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "6caa2adc56810d16ee170617a9f389c6",
     "grade": true,
     "grade_id": "cell-load_data_test5",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Autograder test cell - worth 1 point\n",
    "# runs load_data test5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "54ea358256ed0fb875b7574496a18b09",
     "grade": true,
     "grade_id": "cell-load_data_test6",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Autograder test cell - worth 1 point\n",
    "# runs load_data test6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "f3928f5e46a1a489737dfdc38403af78",
     "grade": true,
     "grade_id": "cell-load_data_test7",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Autograder test cell - worth 1 point\n",
    "# runs load_data test7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "cf63e38609277039fc56c73ad45952e9",
     "grade": false,
     "grade_id": "cell-e5d3f8c58fe5c9f1",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Part Two: Picking a Metric for Evaluation [Not Graded]\n",
    "\n",
    "Since this is a classification problem, there are multiple loss functions or metrics we can use to evaluate. We will use `square_loss` as our loss function since we can always cast a classification problem as regression problem. We have implemented the loss function below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "1de64a8c36bcb98c3ea376557432c9f7",
     "grade": false,
     "grade_id": "cell-37254305636ee0ca",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "def square_loss(pred, truth):\n",
    "    \"\"\"\n",
    "    Calculates the loss between predicted and true labels.\n",
    "    \n",
    "    Input:\n",
    "        pred: n-dimensional vector of predicted labels\n",
    "        truth: n-dimensional vector of true labels\n",
    "        \n",
    "    Output:\n",
    "        loss: average squared loss\n",
    "    \"\"\"\n",
    "    return np.mean((pred - truth)**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "55ec9603c04c5ce17a2b40747c3107d0",
     "grade": false,
     "grade_id": "cell-e422aaa713e45c82",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Part Three: Model Selection [Graded]\n",
    "\n",
    "At this point, we have \n",
    "- Split the data into training set and test set\n",
    "- Understood and loaded the data\n",
    "- Picked a metric for evaluation\n",
    "\n",
    "Now we are ready for model selection!\n",
    "\n",
    "A data scientist would typically try different models such as perceptron, linear regression etc. For simplicity, we restrict our attention to regression tree. Implement the **`test`** function which loads the training and test sets, finds the optimal regression tree trained on `heart_disease_train.csv`, and returns the tree's predictions on `heart_disease_test.csv`. You will be evaluated based on `square_loss`. You will get a full score if the test loss on your classifier is less than **0.18**. You may use any functions that you implemented in the previous projects.\n",
    "\n",
    "_Hint: A few things you can try: selecting the best depth to avoid overfitting, pick the optimal subset of features for your classification model etc._\n",
    "\n",
    "Here are the functions/classes from previous projects available to you:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "37885eaeb648f45bb31a3b942c66f28b",
     "grade": false,
     "grade_id": "cell-c90887080a238f11",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "## Regression Tree\n",
    "# Create a regression with no restriction on its depth\n",
    "# if you want to create a tree of depth k\n",
    "# then call RegressionTree(depth=k)\n",
    "tree = RegressionTree(depth=np.inf)\n",
    "\n",
    "# To fit/train the regression tree\n",
    "tree.fit(X, y)\n",
    "\n",
    "# To use the trained regression tree to make predictions\n",
    "pred = tree.predict(X)\n",
    "\n",
    "## k-Fold Cross Validation\n",
    "depths = [1, 3]\n",
    "\n",
    "# To generate 5 folds for X data\n",
    "indices = generate_kFold(n=X.shape[0], k=5)\n",
    "\n",
    "# To find best depth across the folds\n",
    "best_depth, training_losses, validation_losses = cross_validation(X, y, depths, indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "e792eedd8f288385db814f9c062b64ff",
     "grade": false,
     "grade_id": "cell-test",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def test():\n",
    "    \"\"\"\n",
    "    Loads the training and test sets, trains a regression tree and outputs predictions for the test set.\n",
    "    \n",
    "    Output:\n",
    "        prediction: the prediction of your classifier on the heart_disease_test.csv\n",
    "    \"\"\"\n",
    "    prediction = None\n",
    "    Xtrain, ytrain = load_data(file='heart_disease_train.csv', label=True)\n",
    "    ytrain=ytrain>0\n",
    "    Xtest = load_data(file='heart_disease_test.csv', label=False)\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    #raise NotImplementedError()\n",
    "    tree = RegressionTree(depth = 4)\n",
    "    tree.fit(Xtrain, ytrain)\n",
    "    \n",
    "    return tree.predict(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "5d2d5ce4f46e2e9b0d630057d628fa17",
     "grade": false,
     "grade_id": "cell-test_selftest",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your test loss: 0.2203\n",
      "Running Test: test_loss_test ... ✖ Failed!\n",
      " The output of your function does not match the expected output. Check your code and try again.\n"
     ]
    }
   ],
   "source": [
    "# The following test wil check that your test function returns a loss less than 0.18 on a sample dataset\n",
    "# ground truth:\n",
    "gt = np.array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
    "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
    "\n",
    "pred = test()\n",
    "test_loss = square_loss(pred, gt)\n",
    "print('Your test loss: {:0.4f}'.format(test_loss))\n",
    "\n",
    "def test_loss_test():\n",
    "    return (test_loss < 0.18)\n",
    "\n",
    "runtest(test_loss_test, 'test_loss_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "06e7584adfbe6c3c84f7e45446cb4c35",
     "grade": true,
     "grade_id": "cell-test_test",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Autograder test cell - worth 1 point\n",
    "# runs test function test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
